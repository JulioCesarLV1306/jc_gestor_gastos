{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be307aab",
   "metadata": {},
   "source": [
    "## üì¶ Instalaci√≥n de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a61a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q flask flask-ngrok pyngrok pandas numpy scikit-learn joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb6e23",
   "metadata": {},
   "source": [
    "## üîß Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import json\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbfdb90",
   "metadata": {},
   "source": [
    "## üéØ Configurar Token de Ngrok\n",
    "\n",
    "**IMPORTANTE:** Obt√©n tu token de ngrok en https://dashboard.ngrok.com/get-started/your-authtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e704c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è REEMPLAZA CON TU TOKEN DE NGROK\n",
    "NGROK_AUTH_TOKEN = \"tu_token_aqui\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bdd88",
   "metadata": {},
   "source": [
    "## üß† Clase del Modelo ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c20b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpensePredictionModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.anomaly_detector = None\n",
    "        self.label_encoders = {}\n",
    "        self.feature_names = []\n",
    "        self.metrics = {}\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def prepare_features(self, data):\n",
    "        \"\"\"Preparar features para el modelo\"\"\"\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convertir fecha a datetime\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "        \n",
    "        # Extraer features temporales\n",
    "        df['day_of_week'] = df['fecha'].dt.dayofweek\n",
    "        df['day_of_month'] = df['fecha'].dt.day\n",
    "        df['month'] = df['fecha'].dt.month\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "        df['week_of_month'] = (df['day_of_month'] - 1) // 7 + 1\n",
    "        \n",
    "        # Codificar categor√≠as\n",
    "        if 'categoria' in df.columns:\n",
    "            if 'categoria' not in self.label_encoders:\n",
    "                self.label_encoders['categoria'] = LabelEncoder()\n",
    "                df['categoria_encoded'] = self.label_encoders['categoria'].fit_transform(df['categoria'])\n",
    "            else:\n",
    "                df['categoria_encoded'] = self.label_encoders['categoria'].transform(df['categoria'])\n",
    "        \n",
    "        # Features de usuario\n",
    "        if 'userId' in df.columns:\n",
    "            if 'userId' not in self.label_encoders:\n",
    "                self.label_encoders['userId'] = LabelEncoder()\n",
    "                df['user_encoded'] = self.label_encoders['userId'].fit_transform(df['userId'])\n",
    "            else:\n",
    "                df['user_encoded'] = self.label_encoders['userId'].transform(df['userId'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train(self, training_data, model_config):\n",
    "        \"\"\"Entrenar el modelo con los datos proporcionados\"\"\"\n",
    "        print(f\"üöÄ Iniciando entrenamiento con {len(training_data)} registros...\")\n",
    "        \n",
    "        # Preparar datos\n",
    "        df = self.prepare_features(training_data)\n",
    "        \n",
    "        # Seleccionar features\n",
    "        feature_columns = ['day_of_week', 'day_of_month', 'month', 'is_weekend', \n",
    "                          'week_of_month', 'categoria_encoded']\n",
    "        \n",
    "        if 'user_encoded' in df.columns:\n",
    "            feature_columns.append('user_encoded')\n",
    "        \n",
    "        X = df[feature_columns]\n",
    "        y = df['monto']\n",
    "        \n",
    "        self.feature_names = feature_columns\n",
    "        \n",
    "        # Dividir datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        n_estimators = model_config.get('n_estimators', 100)\n",
    "        max_depth = model_config.get('max_depth', 10)\n",
    "        \n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        self.metrics = {\n",
    "            'mae': float(mean_absolute_error(y_test, y_pred)),\n",
    "            'rmse': float(np.sqrt(mean_squared_error(y_test, y_pred))),\n",
    "            'r2': float(r2_score(y_test, y_pred)),\n",
    "            'accuracy': float(r2_score(y_test, y_pred) * 100),\n",
    "            'training_samples': len(X_train),\n",
    "            'test_samples': len(X_test)\n",
    "        }\n",
    "        \n",
    "        # Entrenar detector de anomal√≠as\n",
    "        self.anomaly_detector = IsolationForest(\n",
    "            contamination=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.anomaly_detector.fit(X)\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"‚úÖ Modelo entrenado exitosamente!\")\n",
    "        print(f\"üìä R¬≤ Score: {self.metrics['r2']:.4f}\")\n",
    "        print(f\"üìâ MAE: ${self.metrics['mae']:.2f}\")\n",
    "        print(f\"üìà RMSE: ${self.metrics['rmse']:.2f}\")\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def predict(self, user_data, days_to_predict=30):\n",
    "        \"\"\"Hacer predicciones para un usuario\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"Modelo no entrenado. Llama a train() primero.\")\n",
    "        \n",
    "        # Preparar features\n",
    "        df = self.prepare_features(user_data)\n",
    "        \n",
    "        # Generar fechas futuras\n",
    "        last_date = df['fecha'].max()\n",
    "        future_dates = [last_date + timedelta(days=i) for i in range(1, days_to_predict + 1)]\n",
    "        \n",
    "        # Crear dataframe de predicci√≥n\n",
    "        predictions = []\n",
    "        \n",
    "        for date in future_dates:\n",
    "            pred_row = {\n",
    "                'day_of_week': date.weekday(),\n",
    "                'day_of_month': date.day,\n",
    "                'month': date.month,\n",
    "                'is_weekend': int(date.weekday() >= 5),\n",
    "                'week_of_month': (date.day - 1) // 7 + 1,\n",
    "                'categoria_encoded': df['categoria_encoded'].mode()[0] if 'categoria_encoded' in df.columns else 0\n",
    "            }\n",
    "            \n",
    "            if 'user_encoded' in df.columns:\n",
    "                pred_row['user_encoded'] = df['user_encoded'].iloc[0]\n",
    "            \n",
    "            pred_df = pd.DataFrame([pred_row])[self.feature_names]\n",
    "            predicted_amount = self.model.predict(pred_df)[0]\n",
    "            \n",
    "            predictions.append({\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'predicted_amount': float(predicted_amount)\n",
    "            })\n",
    "        \n",
    "        # Calcular estad√≠sticas\n",
    "        total_predicted = sum(p['predicted_amount'] for p in predictions)\n",
    "        avg_predicted = total_predicted / len(predictions)\n",
    "        \n",
    "        # Calcular confianza basada en el R¬≤\n",
    "        confidence = self.metrics.get('r2', 0.5) * 100\n",
    "        \n",
    "        return {\n",
    "            'predictions': predictions,\n",
    "            'total_predicted': float(total_predicted),\n",
    "            'average_daily': float(avg_predicted),\n",
    "            'confidence': float(confidence),\n",
    "            'days': days_to_predict\n",
    "        }\n",
    "    \n",
    "    def detect_anomalies(self, expenses):\n",
    "        \"\"\"Detectar gastos an√≥malos\"\"\"\n",
    "        if not self.is_trained or self.anomaly_detector is None:\n",
    "            raise Exception(\"Modelo no entrenado\")\n",
    "        \n",
    "        df = self.prepare_features(expenses)\n",
    "        X = df[self.feature_names]\n",
    "        \n",
    "        # Predecir anomal√≠as (-1 = anomal√≠a, 1 = normal)\n",
    "        predictions = self.anomaly_detector.predict(X)\n",
    "        anomaly_scores = self.anomaly_detector.score_samples(X)\n",
    "        \n",
    "        anomalies = []\n",
    "        for idx, (pred, score) in enumerate(zip(predictions, anomaly_scores)):\n",
    "            if pred == -1:\n",
    "                anomalies.append({\n",
    "                    'index': int(idx),\n",
    "                    'amount': float(df.iloc[idx]['monto']),\n",
    "                    'category': df.iloc[idx].get('categoria', 'Unknown'),\n",
    "                    'date': df.iloc[idx]['fecha'].strftime('%Y-%m-%d'),\n",
    "                    'anomaly_score': float(score),\n",
    "                    'severity': 'high' if score < -0.5 else 'medium'\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'anomalies_found': len(anomalies),\n",
    "            'anomalies': anomalies,\n",
    "            'total_analyzed': len(expenses)\n",
    "        }\n",
    "\n",
    "# Instancia global del modelo\n",
    "model = ExpensePredictionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b78296",
   "metadata": {},
   "source": [
    "## üåê API Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f375541",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Verificar estado de la API\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_trained': model.is_trained,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }), 200\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train_model():\n",
    "    \"\"\"Entrenar el modelo\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        training_data = data.get('training_data', [])\n",
    "        model_config = data.get('model_config', {})\n",
    "        \n",
    "        if not training_data:\n",
    "            return jsonify({'error': 'No training data provided'}), 400\n",
    "        \n",
    "        metrics = model.train(training_data, model_config)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'message': 'Model trained successfully',\n",
    "            'metrics': metrics,\n",
    "            'accuracy': metrics['accuracy']\n",
    "        }), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Hacer predicci√≥n para un usuario\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        user_id = data.get('user_id')\n",
    "        historical_data = data.get('historical_data', [])\n",
    "        days_to_predict = data.get('days_to_predict', 30)\n",
    "        \n",
    "        if not historical_data:\n",
    "            return jsonify({'error': 'No historical data provided'}), 400\n",
    "        \n",
    "        result = model.predict(historical_data, days_to_predict)\n",
    "        result['user_id'] = user_id\n",
    "        result['predicted_amount'] = result['total_predicted']\n",
    "        result['confidence'] = result['confidence']\n",
    "        \n",
    "        return jsonify(result), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/predict_multiple', methods=['POST'])\n",
    "def predict_multiple():\n",
    "    \"\"\"Predicciones para m√∫ltiples categor√≠as\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        user_id = data.get('user_id')\n",
    "        historical_data = data.get('historical_data', [])\n",
    "        categories = data.get('categories', [])\n",
    "        days_to_predict = data.get('days_to_predict', 30)\n",
    "        \n",
    "        predictions_by_category = {}\n",
    "        \n",
    "        for category in categories:\n",
    "            category_data = [d for d in historical_data if d.get('categoria') == category]\n",
    "            if category_data:\n",
    "                pred = model.predict(category_data, days_to_predict)\n",
    "                predictions_by_category[category] = pred\n",
    "        \n",
    "        return jsonify({\n",
    "            'user_id': user_id,\n",
    "            'predictions': predictions_by_category\n",
    "        }), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/detect_anomalies', methods=['POST'])\n",
    "def detect_anomalies():\n",
    "    \"\"\"Detectar gastos an√≥malos\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        expenses = data.get('expenses', [])\n",
    "        \n",
    "        if not expenses:\n",
    "            return jsonify({'error': 'No expenses provided'}), 400\n",
    "        \n",
    "        result = model.detect_anomalies(expenses)\n",
    "        \n",
    "        return jsonify(result), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/metrics', methods=['GET'])\n",
    "def get_metrics():\n",
    "    \"\"\"Obtener m√©tricas del modelo\"\"\"\n",
    "    if not model.is_trained:\n",
    "        return jsonify({'error': 'Model not trained yet'}), 400\n",
    "    \n",
    "    return jsonify(model.metrics), 200\n",
    "\n",
    "@app.route('/recommendations', methods=['POST'])\n",
    "def get_recommendations():\n",
    "    \"\"\"Obtener recomendaciones personalizadas\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        user_data = data.get('user_data', {})\n",
    "        \n",
    "        # An√°lisis b√°sico para recomendaciones\n",
    "        recommendations = [\n",
    "            {\n",
    "                'type': 'budget',\n",
    "                'message': 'Basado en tus patrones de gasto, considera ajustar tu presupuesto',\n",
    "                'priority': 'medium'\n",
    "            },\n",
    "            {\n",
    "                'type': 'savings',\n",
    "                'message': 'Puedes ahorrar m√°s reduciendo gastos en categor√≠as no esenciales',\n",
    "                'priority': 'high'\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return jsonify({\n",
    "            'recommendations': recommendations,\n",
    "            'generated_at': datetime.now().isoformat()\n",
    "        }), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def receive_feedback():\n",
    "    \"\"\"Recibir feedback sobre predicciones\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        # Guardar feedback para mejorar el modelo (implementar persistencia)\n",
    "        print(f\"üìù Feedback recibido: {data}\")\n",
    "        \n",
    "        return jsonify({'status': 'feedback_received'}), 200\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "print(\"‚úÖ API Flask configurada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813d39e",
   "metadata": {},
   "source": [
    "## üöÄ Iniciar Servidor con Ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94321aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar servidor en un thread\n",
    "def run_app():\n",
    "    app.run(port=5000)\n",
    "\n",
    "# Iniciar Flask en background\n",
    "thread = threading.Thread(target=run_app)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "print(\"‚è≥ Esperando a que Flask inicie...\")\n",
    "import time\n",
    "time.sleep(3)\n",
    "\n",
    "# Crear t√∫nel ngrok\n",
    "public_url = ngrok.connect(5000, bind_tls=True)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ¬°SERVIDOR INICIADO EXITOSAMENTE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüì° URL P√∫blica de la API: {public_url}\")\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANTE: Copia esta URL y √∫sala en tu app Flutter:\")\n",
    "print(f\"\\n   colabService.setColabApiUrl('{public_url}');\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n‚úÖ Endpoints disponibles:\")\n",
    "print(f\"   ‚Ä¢ Health Check: {public_url}/health\")\n",
    "print(f\"   ‚Ä¢ Entrenar: {public_url}/train\")\n",
    "print(f\"   ‚Ä¢ Predecir: {public_url}/predict\")\n",
    "print(f\"   ‚Ä¢ M√∫ltiples: {public_url}/predict_multiple\")\n",
    "print(f\"   ‚Ä¢ Anomal√≠as: {public_url}/detect_anomalies\")\n",
    "print(f\"   ‚Ä¢ M√©tricas: {public_url}/metrics\")\n",
    "print(f\"   ‚Ä¢ Recomendaciones: {public_url}/recommendations\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nüí° El servidor se mantendr√° activo mientras esta celda est√© ejecut√°ndose\")\n",
    "print(\"   NO cierres este notebook ni detengas la ejecuci√≥n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4286009",
   "metadata": {},
   "source": [
    "## üß™ Prueba la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Test health check\n",
    "response = requests.get(f\"{public_url}/health\")\n",
    "print(\"üîç Health Check:\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe6d71",
   "metadata": {},
   "source": [
    "## üìä Ejemplo de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f549b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo para entrenar\n",
    "sample_data = [\n",
    "    {'userId': 'user1', 'fecha': '2024-01-01', 'monto': 50.0, 'categoria': 'Comida'},\n",
    "    {'userId': 'user1', 'fecha': '2024-01-02', 'monto': 30.0, 'categoria': 'Transporte'},\n",
    "    {'userId': 'user1', 'fecha': '2024-01-03', 'monto': 100.0, 'categoria': 'Comida'},\n",
    "    {'userId': 'user2', 'fecha': '2024-01-01', 'monto': 75.0, 'categoria': 'Entretenimiento'},\n",
    "    {'userId': 'user2', 'fecha': '2024-01-02', 'monto': 45.0, 'categoria': 'Comida'},\n",
    "]\n",
    "\n",
    "# Entrenar modelo\n",
    "train_response = requests.post(\n",
    "    f\"{public_url}/train\",\n",
    "    json={\n",
    "        'training_data': sample_data,\n",
    "        'model_config': {'n_estimators': 100, 'max_depth': 10}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nüéì Resultado del entrenamiento:\")\n",
    "print(json.dumps(train_response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a00f50",
   "metadata": {},
   "source": [
    "## üîÆ Ejemplo de Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3955f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicci√≥n\n",
    "predict_response = requests.post(\n",
    "    f\"{public_url}/predict\",\n",
    "    json={\n",
    "        'user_id': 'user1',\n",
    "        'historical_data': sample_data[:3],\n",
    "        'days_to_predict': 7\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nüîÆ Predicci√≥n:\")\n",
    "print(json.dumps(predict_response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d54d1f",
   "metadata": {},
   "source": [
    "## üíæ Guardar Modelo (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236bf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo entrenado\n",
    "if model.is_trained:\n",
    "    joblib.dump(model.model, 'expense_prediction_model.pkl')\n",
    "    joblib.dump(model.anomaly_detector, 'anomaly_detector.pkl')\n",
    "    joblib.dump(model.label_encoders, 'label_encoders.pkl')\n",
    "    \n",
    "    print(\"‚úÖ Modelo guardado exitosamente\")\n",
    "    print(\"   ‚Ä¢ expense_prediction_model.pkl\")\n",
    "    print(\"   ‚Ä¢ anomaly_detector.pkl\")\n",
    "    print(\"   ‚Ä¢ label_encoders.pkl\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è El modelo no est√° entrenado a√∫n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490e9a9",
   "metadata": {},
   "source": [
    "## üì• Cargar Modelo Guardado (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo previamente guardado\n",
    "try:\n",
    "    model.model = joblib.load('expense_prediction_model.pkl')\n",
    "    model.anomaly_detector = joblib.load('anomaly_detector.pkl')\n",
    "    model.label_encoders = joblib.load('label_encoders.pkl')\n",
    "    model.is_trained = True\n",
    "    \n",
    "    print(\"‚úÖ Modelo cargado exitosamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è No se encontraron archivos de modelo guardados\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
